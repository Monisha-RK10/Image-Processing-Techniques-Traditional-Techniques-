{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0736448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform bitwise (OR, AND, NOT, XOR) operation\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image1 = np.zeros((500,500,3), np.uint8)\n",
    "image2 = np.zeros((500,500,3), np.uint8)\n",
    "\n",
    "image1 = cv2.rectangle(image1, (100,100), (300,300), (255,255,255), -1)\n",
    "image2 = cv2.rectangle(image2, (200,200), (400,400), (255,255,255), -1)\n",
    "\n",
    "bitwise_OR = cv2.bitwise_or(image1, image2)\n",
    "bitwise_AND = cv2.bitwise_and(image1, image2)\n",
    "bitwise_NOT_image1 = cv2.bitwise_not(image1)\n",
    "bitwise_NOT_image2 = cv2.bitwise_not(image2)\n",
    "bitwise_XOR = cv2.bitwise_xor(image1, image2)\n",
    "\n",
    "cv2.imshow('image1', image1)\n",
    "cv2.imshow('image2', image2)\n",
    "cv2.imshow('bitwise_OR', bitwise_OR)\n",
    "cv2.imshow('bitwise_AND', bitwise_AND)\n",
    "cv2.imshow('bitwise_NOT_image1', bitwise_NOT_image1)\n",
    "cv2.imshow('bitwise_NOT_image2', bitwise_NOT_image2)\n",
    "cv2.imshow('bitwise_XOR', bitwise_XOR)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9043a913",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform simple (binary binary invert, truncated, to zero, to zero invert) thresholding\n",
    "import cv2\n",
    "\n",
    "image_path = r'D:\\ComputerVision_Projects\\Image_Processing_1\\input\\black_white.png'\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.resize(image, (300,300))\n",
    "cv2.imshow('image',image)\n",
    "\n",
    "_, image_threshold = cv2.threshold(image, 50,255, cv2.THRESH_BINARY) #set to 0 if less than threshold\n",
    "_, image_threshold_invert = cv2.threshold(image, 50,255, cv2.THRESH_BINARY_INV) #set to 0 if more than threshold\n",
    "_, image_threshold_truncate = cv2.threshold(image, 127,255, cv2.THRESH_TRUNC) #until 127, the image stays as it is (0-127), \n",
    "#from 127 onward, the image is fixed at 127 throughout the image\n",
    "\n",
    "_, image_threshold_tozero= cv2.threshold(image, 127,255, cv2.THRESH_TOZERO) #until 127, the image stays is fixed at 0, \n",
    "#from 127 onward, the image stays as it is (127-255)\n",
    "_, image_threshold_tozero_invert= cv2.threshold(image, 127,255, cv2.THRESH_TOZERO_INV) #until 127, the image stays as it is \n",
    "#(0-127), from 127 onward, the image is fixed at 0\n",
    "\n",
    "cv2.imshow('image_threshold',image_threshold)\n",
    "cv2.imshow('image_threshold_invert',image_threshold_invert)\n",
    "cv2.imshow('image_threshold_truncate',image_threshold_truncate)\n",
    "cv2.imshow('image_threshold_tozero',image_threshold_tozero)\n",
    "cv2.imshow('image_threshold_tozero_invert',image_threshold_tozero_invert)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a37106",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform adaptive (mean, gaussian) thresholding\n",
    "import cv2\n",
    "\n",
    "image_path = r'D:\\ComputerVision_Projects\\Image_Processing_1\\input\\page.jpg'\n",
    "image = cv2.imread(image_path,0)\n",
    "image = cv2.resize(image,(500,500))\n",
    "print('image size',image.shape)\n",
    "\n",
    "_,image_threshold_simple = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "image_threshold_adaptive_mean = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "#number of pixels grouped = 11 (odd)\n",
    "image_threshold_adaptive_gaussian = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "cv2.imshow('image', image)\n",
    "cv2.imshow('image_threshold_simple', image_threshold_simple)\n",
    "cv2.imshow('image_threshold_adaptive_mean', image_threshold_adaptive_mean)\n",
    "cv2.imshow('image_threshold_adaptive_gaussian', image_threshold_adaptive_gaussian)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f7afea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform erosion and dialation (need white objects on the black background)\n",
    "import cv2\n",
    "import numpy as np\n",
    "image_path = r'D:\\ComputerVision_Projects\\Image_Processing_1\\input\\color_balls.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "_,image_mask = cv2.threshold(image_gray, 45, 255, cv2.THRESH_BINARY) \n",
    "kernel = np.ones((3,3), np.uint8)\n",
    "\n",
    "image_erosion = cv2.erode(image_mask,kernel)\n",
    "image_dilation = cv2.dilate(image_mask,kernel)\n",
    "\n",
    "cv2.imshow('image',image)\n",
    "cv2.imshow('image_mask',image_mask)\n",
    "cv2.imshow('image_erosion',image_erosion)\n",
    "cv2.imshow('image_dilation',image_dilation)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20b8b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform opening and closing (need white objects on the black background)\n",
    "import cv2\n",
    "import numpy as np\n",
    "image_path = r'D:\\ComputerVision_Projects\\Image_Processing_1\\input\\color_balls.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "image_gray = cv2.imread(image_path,0)\n",
    "\n",
    "_,image_mask = cv2.threshold(image_gray, 30, 255, cv2.THRESH_BINARY)\n",
    "kernel = np.ones((2,2),np.uint8)\n",
    "#open,close,gradient need image in black and white\n",
    "image_open = cv2.morphologyEx(image_mask, cv2.MORPH_OPEN, kernel)\n",
    "image_close = cv2.morphologyEx(image_mask, cv2.MORPH_CLOSE, kernel)\n",
    "image_gradient = cv2.morphologyEx(image_mask, cv2.MORPH_GRADIENT, kernel)\n",
    "#top hat,black hat do not need image in black and white\n",
    "image_top_hat = cv2.morphologyEx(image, cv2.MORPH_TOPHAT, kernel)\n",
    "image_black_hat = cv2.morphologyEx(image, cv2.MORPH_BLACKHAT, kernel)\n",
    "\n",
    "cv2.imshow('image',image)\n",
    "cv2.imshow('image_mask',image_mask)\n",
    "cv2.imshow('image_open',image_open)\n",
    "cv2.imshow('image_close',image_close)\n",
    "cv2.imshow('image_gradient',image_gradient)\n",
    "cv2.imshow('image_top_hat',image_top_hat)\n",
    "cv2.imshow('image_black_hat',image_black_hat)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0c35aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform smoothing by applying different low pass filters\n",
    "import cv2\n",
    "image_path1 = r'D:\\ComputerVision_Projects\\Image_Processing_1\\input\\noisy.jpg'\n",
    "image = cv2.imread(image_path1)\n",
    "\n",
    "kernel = np.ones((5,5),np.float32)/25\n",
    "image_filter_2D = cv2.filter2D(image,-1,kernel)\n",
    "image_blur = cv2.blur(image,(5,5)) \n",
    "image_gaussian_blur = cv2.GaussianBlur(image,(5,5),0)\n",
    "image_median = cv2.medianBlur(image,5)\n",
    "image_bilateral = cv2.bilateralFilter(image,9,75,75)\n",
    "\n",
    "cv2.imshow('image',image)\n",
    "cv2.imshow('image_filter_2D',image_filter_2D)\n",
    "cv2.imshow('image_blur',image_blur)\n",
    "cv2.imshow('image_gaussian_blur',image_gaussian_blur)\n",
    "cv2.imshow('image_median',image_median)\n",
    "cv2.imshow('image_bilateral',image_bilateral)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15788579",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform edge detection by applying different high pass filters\n",
    "import cv2\n",
    "image_path = r'D:\\ComputerVision_Projects\\Image_Processing_1\\input\\building.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#sobel (gradient based)\n",
    "image_sobel_x = cv2.Sobel(image_gray, cv2.CV_64F, 1,0, ksize=3)\n",
    "image_sobel_y = cv2.Sobel(image_gray, cv2.CV_64F, 0,1, ksize=3)\n",
    "#converting back to CV_8U\n",
    "image_sobel_x = np.uint8(np.absolute(image_sobel_x))\n",
    "image_sobel_y = np.uint8(np.absolute(image_sobel_y))\n",
    "#combine both sobel x and y \n",
    "image_sobel = cv2.bitwise_or(image_sobel_x,image_sobel_y)\n",
    "\n",
    "#laplacian (second gradient based)\n",
    "image_laplacian = cv2.Laplacian(image_gray, cv2.CV_64F, ksize=3)\n",
    "#converting back to CV_8U\n",
    "image_laplacian = np.uint8(np.absolute(image_laplacian))\n",
    "\n",
    "cv2.imshow('image_sobel_x',image_sobel_x)\n",
    "cv2.imshow('image_sobel_y',image_sobel_y)\n",
    "cv2.imshow('image_sobel',image_sobel)\n",
    "cv2.imshow('image_laplacian',image_laplacian)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46268f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Morphological Transformation\n",
    "#Dilation adds pixels to the boundaries of objects in an image, while erosion removes pixels on object boundaries \n",
    "#Number of pixels added/removed from the objects in an image depends on the size and shape of the structuring element(kernel)\n",
    "#Erosion - The kernel runs over every pixel of the image. If all the pixels that are overlapping with the kernel happen \n",
    "#to be ‘1’s, no change occurs. But, if any of the overlapping pixels happen to be ‘0’ the pixel that is overlapping with \n",
    "#the (1,1) element of the kernel is set to ‘0’. Removes white noises,\n",
    "#Dilation - The kernel is running over the image, if any element of the matrix come across with value ‘1’ of the image, \n",
    "#the pixel which is overlapped with the kernel[1][1] element is turned to ‘1’.Useful in joining broken parts of an object\n",
    "#Opening - Erosion followed by dilation.Removes noise\n",
    "#Closing - Reverse of Opening, dilation followed by erosion.Closes small holes inside the foreground objects\n",
    "#Morphological Gradient - It is the difference between dilation and erosion of an image\n",
    "#Top Hat - It is the difference between input image and opening of the image\n",
    "#Black Hat - It is the difference between input image and the closing of the image\n",
    "\n",
    "#References\n",
    "#https://medium.com/@sasasulakshi/opencv-morphological-dilation-and-erosion-fab65c29efb3\n",
    "#https://docs.opencv.org/3.4/d9/d61/tutorial_py_morphological_ops.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c8dd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Smoothing Techniques\n",
    "#Filter2D -  Equal weightage is given to the neighbouring pixels\n",
    "#Blur(Average/Box filter) - Takes average of the output pixels under the kernel size\n",
    "#Gaussian blur - Gaussian gives more importance to the nearest neighbor for computing the output, odd size kernel and\n",
    "#standard deviation need to be passed. Fnction of space\n",
    "#Median - Non-linear filter, robust to outliers, removes salt and pepper noise\n",
    "#Bilateral - Non linear filter, preserves sharp edges, slower, function of space and pixel difference. It has:\n",
    "#sigmaColor: Value in the color space, the higher the value, the more colors that are further apart begin to mix.\n",
    "#sigmaSpace: Value in coordinate space, the higher the value, the more pixels are mixed together, \n",
    "#provided their colors are in the sigmaColor range\n",
    "\n",
    "#References\n",
    "#https://www.geeksforgeeks.org/python-opencv-filter2d-function/\n",
    "#https://docs.opencv.org/4.x/d4/d13/tutorial_py_filtering.html\n",
    "#https://www.geeksforgeeks.org/python-bilateral-filtering/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1670a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Edge detection (convert the image into gray)\n",
    "#Sobel(x,y) - It is applied to the image to highlight the edges by calculating the gradient intensity\n",
    "#Laplacian - An edge detector used to compute the second derivatives of an image, measuring the rate at which the first \n",
    "#derivatives change. This determines if a change in adjacent pixel values is from an edge or continuous progression, but\n",
    "#requires additional smoothing to handle noise effectively"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
